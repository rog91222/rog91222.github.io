<!DOCTYPE html>




<html class="theme-next mist" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Python,爬虫,Scrapy,Toolkit," />










<meta name="keywords" content="Python,爬虫,Scrapy,Toolkit">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy爬虫状态反馈组件 v1.0.0">
<meta property="og:url" content="http://blog.webmad.net/2018/03/12/1802-爬虫日志工具/index.html">
<meta property="og:site_name" content="Hugh Dong">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/abstract.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/1.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/6.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/4.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/5.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/7.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/2.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/18.02.28.1/3.jpg">
<meta property="og:image" content="http://blog.webmad.net/images/guide.png">
<meta property="og:updated_time" content="2018-05-05T16:01:11.773Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy爬虫状态反馈组件 v1.0.0">
<meta name="twitter:image" content="http://blog.webmad.net/images/18.02.28.1/abstract.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"right","display":"remove","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.webmad.net/2018/03/12/1802-爬虫日志工具/"/>





  <title>Scrapy爬虫状态反馈组件 v1.0.0 | Hugh Dong</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?bbf71a40a5a6bb7e9c203f4b44b1f1d8";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hugh Dong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">于学习中挣扎,一生以贯之</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.webmad.net/2018/03/12/1802-爬虫日志工具/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hugh Dong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hugh Dong">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Scrapy爬虫状态反馈组件 v1.0.0</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <!--<span class="post-meta-item-text">发表于</span>-->
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-12T00:00:00+08:00">
                2018-03-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <!--<span class="post-meta-item-text">分类于</span>-->
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/「数据」沙里淘金/" itemprop="url" rel="index">
                    <span itemprop="name">「数据」沙里淘金</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="/images/18.02.28.1/abstract.jpg" alt="img_noborder"><br><a id="more"></a></p>
<blockquote>
<p>爬虫服务在服务器上跑着，心里面难免会犯嘀咕，<br>爬虫死掉了怎么办？<br>爬虫漏了数据怎么办？<br>爬虫被网站封禁了怎么办？<br>目标网站挂了怎么办？<br>返回页面错误或被跳转怎么办？<br>…</p>
</blockquote>
<p>以上来自一个被迫害妄想症患者的自白(误)<br>一次性爬取数据可以通过人工看日志来判断，不行就多爬几遍，<br>但如果是放在服务器上定时爬取的服务怎么办？尤其是已经部署在Docker中的爬虫服务。<br>如果每天都登进服务器查看Scrapy本地的日志信息，还是很麻烦的。<br>那么我们就需要一个特定的日志来存放我们的统计数据，每天爬取完毕后发送邮件给管理员。<br>这样的话爬虫出现问题时管理员就能很快知道，还要能够统计爬取的数据。<br>本文主要描述尝试在Scrapy爬虫的过程中构建工具的思路与体验，代码写的太水就算了(捂脸)<br>在Scrapy框架中本身内置<a href="https://docs.scrapy.org/en/latest/topics/logging.html" target="_blank" rel="external">Logging</a>，但因为是初学Scrapy，不会构建自己的框架。<br>因为Logging模块「Level Info」输出就会多出很多无用的信息，排版不清晰和没法提醒等问题。<br>所以在Scrapy.logging输出日志到文件的基础上，写了自己的日志统计工具来监控爬虫的状态。</p>
<h3 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h3><p>在爬虫书写的过程中遇到的问题还是很多的，比如：</p>
<blockquote>
<p>目标网站宕机或请求错误(404,500,503)<br>指定DOM不存在或Response.text返回错误内容<br>网站请求池过载<br>触发假数据或IP被封禁<br>数据库报错或操作失败<br>…</p>
</blockquote>
<p>除此之外还希望能够统计以下的数据，比如：</p>
<blockquote>
<p>爬取成功的分页条数<br>爬过的信息条数<br>已有数据的重复条数<br>爬虫开始时间 / 结束时间 / 耗时<br>…</p>
</blockquote>
<p>图的左边是爬虫的基本流程，中间部分是触发事件，右侧是执行的统计操作<br><a href="/images/18.02.28.1/1.jpg">查看大图</a><br><img src="/images/18.02.28.1/1.jpg" alt="img_shadow"></p>
<p>整理之后得到以下JSON格式来存储统计信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">stat.log = &#123;</div><div class="line">    &apos;time&apos;: &#123;                # 全局时间</div><div class="line">        &apos;start_time&apos;: 0,         # 爬虫开始时间</div><div class="line">        &apos;end_time&apos;: 0,           # 爬虫结束时间</div><div class="line">        &apos;consume_time&apos;: 0,       # 爬虫总耗时</div><div class="line">    &#125;,</div><div class="line">    &apos;spider1&apos;: &#123;             # 爬虫1的信息</div><div class="line">        &apos;request_sucess&apos;: 0,     # 分页请求成功</div><div class="line">        &apos;request_error&apos;: 0,      # 分页请求失败</div><div class="line">        &apos;data_crawl&apos;: 0,         # 爬过的数据项 (爬虫发现的总条目</div><div class="line">        &apos;data_new&apos;: 0,           # 新增的数据项 (不重复并成功写库的</div><div class="line">        &apos;data_error&apos;: 0,         # 错误的数据项 (数据项内容请求错误的</div><div class="line">        &apos;data_illegal&apos;: 0,       # 违规的数据项 (数据项格式检查错误的</div><div class="line">        &apos;data_repeat&apos;: 0,        # 重复的数据项 (数据库中已有重复数据</div><div class="line">        &apos;db_error&apos;: 0,           # 数据库错误项 (数据库连接错误等</div><div class="line">        &apos;db_operate&apos;: 0,         # 数据库操作项 (读写等操作返回值异常</div><div class="line">    &#125;,</div><div class="line">    &apos;spider2&apos;: &#123;             # 爬虫2的信息</div><div class="line">        &apos;request_success&apos;: 0,    # ...</div><div class="line">        # ...</div><div class="line">    &#125;</div><div class="line">    # ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="收集反馈"><a href="#收集反馈" class="headerlink" title="收集反馈"></a>收集反馈</h3><p>Scrapy的全局执行可以异步执行所有爬虫，<br>在打开爬虫前初始化时间，结束后记录结束时间并计算耗时<br><img src="/images/18.02.28.1/6.jpg" alt="img_shadow"></p>
<p>Scrapy管道(pipelines.py)中有从父类继承来的方法 open_spider()，<br>在管道中实例化类，实例化后存储json中初始化对应数据字段。<br>从数据库中提取已爬取的条数，并打印反馈。<br><img src="/images/18.02.28.1/4.jpg" alt="img_shadow"></p>
<p>Scrapy中间件(middlewares.py)中爬虫打开和页面请求进行标注。<br>spider_opened() 触发显示爬虫打开。<br>process_spider_input() 当页面请求后触发方法，判断如果是200成功请求，记录请求成功。<br>在记录请求成功后输出当前爬虫的json日志，防止爬虫进程意外中断看不到记录的情况。<br>process_spider_exception() 当页面404,500,503…异常时触发该方法，记录请求错误。<br><img src="/images/18.02.28.1/5.jpg" alt="img_shadow"></p>
<p>在爬虫执行中判断数据的重复/缺少字段/错误/新增等情况<br><img src="/images/18.02.28.1/7.jpg" alt="img_shadow"></p>
<h3 id="日志输出"><a href="#日志输出" class="headerlink" title="日志输出"></a>日志输出</h3><p>日志的输出情况如下  <a href="/images/18.02.28.1/2.jpg">查看大图</a><br><img src="/images/18.02.28.1/2.jpg" alt="img_shadow"><br>日志的结尾的输出  <a href="/images/18.02.28.1/3.jpg">查看大图</a><br><img src="/images/18.02.28.1/3.jpg" alt="img_shadow"></p>
<h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><p>代码写的实在太糟糕了，初学见谅<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div></pre></td><td class="code"><pre><div class="line"># statistics.py</div><div class="line"># update /18.03.12.1</div><div class="line"></div><div class="line">import time</div><div class="line">import json</div><div class="line">import logging</div><div class="line"></div><div class="line">class Statistics():</div><div class="line">    CUR_LOG = &#123;</div><div class="line">        &apos;time&apos;: &#123;</div><div class="line">            &apos;start_time&apos;: 0,  # 开始时间</div><div class="line">            &apos;end_time&apos;: 0,  # 结束时间</div><div class="line">            &apos;consume_time&apos;: 0,  # 共耗时</div><div class="line">        &#125;,</div><div class="line">        # &apos;spider1&apos;: &#123;</div><div class="line">        #     &apos;request_sucess&apos;: 0,  # 请求成功(分页数)</div><div class="line">        #     &apos;request_error&apos;: 0,  # 请求错误</div><div class="line">        #     &apos;data_crawl&apos;: 0,  # 爬取到的数量</div><div class="line">        #     &apos;data_new&apos;: 0,  # 获取到的新数据</div><div class="line">        #     &apos;data_error&apos;: 0,  # 数据出错</div><div class="line">        #     &apos;data_illegal&apos;: 0,  # 数据格式错误</div><div class="line">        #     &apos;data_repeat&apos;: 0,  # 重复的数据</div><div class="line">        #     &apos;db_error&apos;: 0,  # 数据库系统错误</div><div class="line">        #     &apos;db_operate&apos;: 0,  # 数据库操作返回错误</div><div class="line">        # &#125;,</div><div class="line">    &#125;</div><div class="line">    logger = logging.getLogger(&apos;stat&apos;)</div><div class="line"></div><div class="line">    def __init__(self, name=None):</div><div class="line">        if name:</div><div class="line">            self.CUR_LOG[name] = &#123;&#125;</div><div class="line">            self.CUR_LOG[name][&apos;request_success&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;request_error&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;data_crawl&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;data_new&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;data_error&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;data_illegal&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;data_repeat&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;db_error&apos;] = 0</div><div class="line">            self.CUR_LOG[name][&apos;db_operate&apos;] = 0</div><div class="line"></div><div class="line">    def start_time(self):</div><div class="line">        self.CUR_LOG[&apos;time&apos;][&apos;start_time&apos;] = time.time()</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(&apos;all&apos;) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[start_time]&apos;) \</div><div class="line">                            + time.strftime(&apos;%Y-%m-%d-%H:%M:%S&apos;, time.localtime()))</div><div class="line"></div><div class="line">    def end_time(self):</div><div class="line">        self.CUR_LOG[&apos;time&apos;][&apos;end_time&apos;] = time.time()</div><div class="line">        self.CUR_LOG[&apos;time&apos;][&apos;consume_time&apos;] \</div><div class="line">            = self.CUR_LOG[&apos;time&apos;][&apos;end_time&apos;] \</div><div class="line">              - self.CUR_LOG[&apos;time&apos;][&apos;start_time&apos;]</div><div class="line"></div><div class="line">        self.CUR_LOG[&apos;time&apos;][&apos;start_time&apos;] \</div><div class="line">            = time.strftime(&apos;%Y-%m-%d-%H:%M:%S&apos;, time.localtime(self.CUR_LOG[&apos;time&apos;][&apos;start_time&apos;]))</div><div class="line">        self.CUR_LOG[&apos;time&apos;][&apos;end_time&apos;] \</div><div class="line">            = time.strftime(&apos;%Y-%m-%d-%H:%M:%S&apos;, time.localtime(self.CUR_LOG[&apos;time&apos;][&apos;end_time&apos;]))</div><div class="line"></div><div class="line">        hours = &apos;&#123;:0&gt;2s&#125;&apos;.format(str(int(self.CUR_LOG[&apos;time&apos;][&apos;consume_time&apos;] // 3600)))</div><div class="line">        minutes = &apos;&#123;:0&gt;2s&#125;&apos;.format(str(int((self.CUR_LOG[&apos;time&apos;][&apos;consume_time&apos;] // 60) % 60)))</div><div class="line">        seconds = &apos;&#123;:0&gt;2s&#125;&apos;.format(str(int(self.CUR_LOG[&apos;time&apos;][&apos;consume_time&apos;] % 60)))</div><div class="line">        self.CUR_LOG[&apos;time&apos;][&apos;consume_time&apos;] = hours + &apos;:&apos; + minutes + &apos;:&apos; + seconds</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(&apos;all&apos;) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[end_time]&apos;) \</div><div class="line">                            + time.strftime(&apos;%Y-%m-%d-%H:%M:%S&apos;, time.localtime()))</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(&apos;all&apos;) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[consume_time]&apos;) \</div><div class="line">                            + self.CUR_LOG[&apos;time&apos;][&apos;consume_time&apos;])</div><div class="line"></div><div class="line">    def add_request_success(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;request_success&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[request_success]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def add_request_error(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;request_error&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[request_error]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def add_data_crawl(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;data_crawl&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[data_crawl]&apos;) \</div><div class="line">                            + str(num))</div><div class="line"></div><div class="line">    def add_data_new(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;data_new&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[data_new]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def add_data_error(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;data_error&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[data_error]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def add_data_illegal(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;data_illegal&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[data_illegal]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def add_data_repeat(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;data_repeat&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[data_repeat]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def add_db_error(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;db_error&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[db_error]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def add_db_operate(self, name, msg=&apos;&apos;, num=1):</div><div class="line">        self.CUR_LOG[name][&apos;db_operate&apos;] += num</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[db_operate]&apos;) \</div><div class="line">                            + str(msg).replace(&apos;\n&apos;, &apos; &apos;))</div><div class="line"></div><div class="line">    def json_display(self, name=None):</div><div class="line">        if name:</div><div class="line">            self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                                + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[json_display]&apos;) \</div><div class="line">                                + str(self.CUR_LOG[name]))</div><div class="line">        else:</div><div class="line">            self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(&apos;all&apos;) \</div><div class="line">                                + &apos;&#123;: &lt;17s&#125; \n&apos;.format(&apos;[json_display]&apos;) \</div><div class="line">                                + str(json.dumps(self.CUR_LOG, indent=4)))</div><div class="line"></div><div class="line">    def crawled_display(self, name, msg=&apos;&apos;):</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[crawled_number]&apos;) \</div><div class="line">                            + str(msg))</div><div class="line"></div><div class="line">    def open_display(self, name, msg=&apos;&apos;):</div><div class="line">        self.logger.warning(&apos;&#123;: &lt;6s&#125;&apos;.format(name) \</div><div class="line">                            + &apos;&#123;: &lt;17s&#125; &apos;.format(&apos;[opened]&apos;))</div></pre></td></tr></table></figure></p>
<center><br><a href="mailto:hugh.dong@outlook.com" class="my-btn-contact" target="_blank" rel="external">联系博主</a><br><br></center>

<p><img src="/images/guide.png" alt="img_guide"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
            <a href="/tags/爬虫/" rel="tag"># 爬虫</a>
          
            <a href="/tags/Scrapy/" rel="tag"># Scrapy</a>
          
            <a href="/tags/Toolkit/" rel="tag"># Toolkit</a>
          
        </div>
      
      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/12/1803-爬虫清洗工具/" rel="next" title="爬虫自然语言清洗组件 v1.0.0">
                <i class="fa fa-chevron-left"></i> 爬虫自然语言清洗组件 v1.0.0
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/14/1803-Vue点击滚动页面/" rel="prev" title="「Vue」点击滚动页面与$nextTick问题解决">
                「Vue」点击滚动页面与$nextTick问题解决 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner" style="padding-top:10px;">
        <div class="copyright" style="float:left">
  <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <span id="busuanzi_container_site_uv" class="site-uv">
    <i class="fa fa-user"></i>
    <span id="busuanzi_value_site_uv"></span>
  </span>
  <span id="busuanzi_container_site_pv" class="site-pv">
      <i class="fa fa-eye"></i>
      <span id="busuanzi_value_site_pv"></span>
  </span>
</div>
<div class="copyright" style="float:right">


&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
  </span>
  <a href="http://www.miitbeian.gov.cn">苏ICP备16043304号</a>

  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div>

-->


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  
  

  

  

  

</body>
</html>
